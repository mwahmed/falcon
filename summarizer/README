README


This module contains the code that returns a summary based on tf-idf scores and cuewords used from G. Murray's thesis.

data:
	This directory will contain the documents that can be used as reference to calculate tf-idf scores.

df.py:
	This module calculates the number of occurences of each term in each document contained in the data directory
	The number of occurences of each word is written to the file saved_idf.txt

tfidf.py:
	This module contains a function that takes a transcription as input and calculates tf and idf values for every word appearing in the document.

	Then, it calculates the tf-idf score per sentence, and finds the avg per sentence tf-idf score. Sentences with tf-idf scores greater than the average are selected to be part of the summary.


cuewords.py:
	This module checks the transcript to see if any sentences contain cuewords and includes those sentences in the summary. Cuewords are loaded into
	a dictionary from the cuewords.txt file.

Running instructions:
	df.py:
		python df.py /path/to/<saved_df_scores_file> /path/to/<df_meta_file>

	tfidf should be imported by the module calling it	


TODO:
	- Use NLTK POS tagging to handle the unique_words in transcription
	- Clean up the df.py script to parse the input file properly. Check with Veneris and/or Zissis whether we can keep using NLTK corpora before proceeding with this. 
		- If they give us a go-ahead, then also write a smarter parsing logic for the brown_nolines.txt file